% \begin{description}[leftmargin=-1\labelwidth]
% \item[\textsc{Overview}] \lipsum[1]
% \end{description}

From our vantage point in 2019, it seems as if the study of cultural transmission is a formalized, model-driven, highly interdisciplinary field, encompassing the ``hard science'' side of most of the traditional social sciences including psychology, economics, and anthropology.  The field is growing and maturing, creating bridges between the social sciences, cognitive science, and the behavioral side of evolutionary biology, leading to a deeper conception of ``cultural evolution'' than past attempts to import Darwinian ideas into the social sciences.  Anthropology can rightly claim a central place in introducing and elaborating the idea of the ``transmission'' of culture, and it is the only discipline among those listed here for which cultural transmission is---and has been, for more than a century---a \emph{central organizing concept} for the discipline \citep{lyman2008cultural}.  And within anthropology itself, archaeology has been central to the framing of cultural transmission as one of our discipline's central pillars both in terms of theory and by providing evidence for the spatio-temporal structure of the products of transmission.

And yet, despite our long history with the concept, and despite a plethora of recent works which provide formalized models and tools, we struggle to use our models to explain the archaeological record we observe in convincing, testable ways.  Kandler and Shennan \citeyearpar{Kandler20150905} note that even the most studied case---ceramic type frequencies from the Merzbach \emph{Linearbandkeramik} in Germany---has produced conflicting results, with some studies consistent with neutral models, and others rejecting neturality in favor of anti-conformist transmission models.  This failure to achieve clarity is not due to lack of theoretical sophistication; the methods involved having evolved well beyond simple tests of neutrality borrowed from population genetics in favor of non-equilibrium and generative models combined with sophisticated Bayesian methods and large amounts of computational resources.  

Some of our issue with empirical sufficiency and connecting models to data arises because of our choice of models and hypotheses, if we are being honest with ourselves.  The shadow of Boyd and Richerson's \citeyearpar{BR1985} pioneering book is understandably quite long, since it (along with neutral theory from theoretical population genetics) gave us a quantitative framework within which to pose, and potentially answer, questions about cultural transmission.  We have been content in most cases to assume that cultural transmission models written in the language of social psychology should also directly speak the language of class frequencies in artifact assemblages.  In most cases, this is an unreasonable expectation. 

The phenomena we seek to explain in archaeology are always aggregated in various ways; at a minimum the typical archaeological deposit is a time averaged record of many events of occupation and activity.  It may be unreasonable to expect that a highly aggregated and time averaged record should be cleanly informative about the average psychological and cognitive biases of past populations.  A great deal of recent work has focused on the issue of \textit{equifinality} between different models of cognitive bias, attempting to quantify the degree to which we may be able to distinguish theoretical models given varying amounts of aggregation.  My own early work in this area forms the first case study presented in this dissertation.

Equifinality can occur for many reasons beyond simply time averaging, and it is a phenomenon which we cannot fully eliminate.  When it occurs, however, we must understand why, and what it is telling us about our models, the observational units we're measuring to create data with which we confront models (in addition to issues such as sample size).  Equifinality arises for several principal reasons, which are linked respectively, to the ideas of \textit{dynamic sufficiency} and \textit{empirical sufficiency} of our theories \citep{Lewontin1974}.

Equifinality may be \textit{structural} and a feature of our models and the way they represent the phenomena we are analyzing.  It is simply the case that two models may make the same distributional predictions about the same observable variables.  In such cases, we cannot tell the two models apart from observations of that variable or set of variables.  In this case, our set of models is dynamically insufficient in a very fundamental way. 

(EXAMPLE from archy models -- different things that lead to power law frequency distributions - Rorabaugh?)


A second major source of equifinality is that our models might make distinguishable predictions given various ``pure'' states and parameter values, but converge strongly given more realistic population states.  We often make simplifying assumptions when we formulate models, often to gain analytic tractability or apply a simple model which has already been studied in another field, but has the same mathematical structure (this is extremely prevalent in theoretical population genetics, and thus in the borrowings made into cultural transmission theory).  Such simplifications have been critical to both population genetics and cultural transmission theory.  Without them, Neiman's \citeyearpar{Neiman1995} seminal contribution would not have been possible, giving rise to a rich lineage of work applying the implications of neutral theory to artifact class frequency distributions (including some of my own early work, e.g., \citealp{Lipo1997}).  But nobody really believes that real populations are composed of individuals who are all ``conformists'' or essentially unbiased in their adoption of traits, or any other ``mode'' we have collectively modeled in the cultural transmission literature.  Real populations are always mixtures of people with varying cognitive biases (and, of course, our deployment of various cognitive biases changes situationally, and our tendency to have specific biases changes over the course of one's lifetime).  The second case study in this dissertation begins the study of such issues, using machine learning methods to determine what the limits of our ability to discriminate among data generating processes may be given realistic mixtures and issues such as sample size.  


** what this means for choice of variables - since that's a key conclusion in the classifier paper

** third cause of equifinality is in the choice of variables or observational units.  This leads to two main threads of research, designed to get away from the sole fixation on trait frequency distributions.  

** seriation

** structured information models  




so long as we do not examine the observational units we use, and expand our toolkit for generating the data we need to test our models \citep{tostevin2019content}.  



My own recent work is aimed at evaluating the potential for ''coarse graining'' cultural transmission models to archaeological scales, which means first and foremost, forming a new set of ''observable'' units which are appropriate to the diachronic, aggregated, and time averaged empirical record we study.  This dissertation is a progress report on forming such observables and examining how to use them to study the kind of data we \emph{actually have}, not the data that would make our task easier---or in other words, the data we \emph{wish} we had. 







